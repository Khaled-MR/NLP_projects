{"metadata":{"accelerator":"GPU","colab":{"name":"neural_machine_translation_with_transformer","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# English-to-Spanish translation with a sequence-to-sequence Transformer\n\n**Author:** [fchollet](https://twitter.com/fchollet)<br>\n**Date created:** 2021/05/26<br>\n**Last modified:** 2023/02/25<br>\n**Description:** Implementing a sequence-to-sequence Transformer and training it on a machine translation task.","metadata":{"id":"u_YtO3YqLQmL"}},{"cell_type":"markdown","source":"## Introduction\n\nIn this example, we'll build a sequence-to-sequence Transformer model, which\nwe'll train on an English-to-Spanish machine translation task.\n\nYou'll learn how to:\n\n- Vectorize text using the Keras `TextVectorization` layer.\n- Implement a `TransformerEncoder` layer, a `TransformerDecoder` layer,\nand a `PositionalEmbedding` layer.\n- Prepare data for training a sequence-to-sequence model.\n- Use the trained model to generate translations of never-seen-before\ninput sentences (sequence-to-sequence inference).\n\nThe code featured here is adapted from the book\n[Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)\n(chapter 11: Deep learning for text).\nThe present example is fairly barebones, so for detailed explanations of\nhow each building block works, as well as the theory behind Transformers,\nI recommend reading the book.","metadata":{"id":"hTevd4dYLQmO"}},{"cell_type":"markdown","source":"## Setup","metadata":{"id":"929UjDdrLQmP"}},{"cell_type":"code","source":"# We set the backend to TensorFlow. The code works with\n# both `tensorflow` and `torch`. It does not work with JAX\n# due to the behavior of `jax.numpy.tile` in a jit scope\n# (used in `TransformerDecoder.get_causal_attention_mask()`:\n# `tile` in JAX does not support a dynamic `reps` argument.\n# You can make the code work in JAX by wrapping the\n# inside of the `get_causal_attention_mask` method in\n# a decorator to prevent jit compilation:\n# `with jax.ensure_compile_time_eval():`.\nimport os\n\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n\nimport pathlib\nimport random\nimport string\nimport re\nimport numpy as np\n\nimport tensorflow.data as tf_data\nimport tensorflow.strings as tf_strings\n\nimport keras\nfrom keras import layers\nfrom keras import ops\nfrom keras.layers import TextVectorization\n","metadata":{"id":"69K1wLMhLQmP","execution":{"iopub.status.busy":"2024-09-19T17:05:08.133217Z","iopub.execute_input":"2024-09-19T17:05:08.133958Z","iopub.status.idle":"2024-09-19T17:05:20.266444Z","shell.execute_reply.started":"2024-09-19T17:05:08.133923Z","shell.execute_reply":"2024-09-19T17:05:20.265491Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Downloading the data\n\nWe'll be working with an English-to-Spanish translation dataset\nprovided by [Anki](https://www.manythings.org/anki/). Let's download it:","metadata":{"id":"XgX_wI8JLQmR"}},{"cell_type":"code","source":"text_file = keras.utils.get_file(\n    fname=\"spa-eng.zip\",\n    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n    extract=True,\n)\ntext_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\"","metadata":{"id":"P7J5StahLQmR","execution":{"iopub.status.busy":"2024-09-19T17:05:29.403249Z","iopub.execute_input":"2024-09-19T17:05:29.404149Z","iopub.status.idle":"2024-09-19T17:05:30.338936Z","shell.execute_reply.started":"2024-09-19T17:05:29.404109Z","shell.execute_reply":"2024-09-19T17:05:30.338154Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Parsing the data\n\nEach line contains an English sentence and its corresponding Spanish sentence.\nThe English sentence is the *source sequence* and Spanish one is the *target sequence*.\nWe prepend the token `\"[start]\"` and we append the token `\"[end]\"` to the Spanish sentence.","metadata":{"id":"DVXgxm6nLQmS"}},{"cell_type":"code","source":"with open(text_file) as f:\n    lines = f.read().split(\"\\n\")[:-1]\ntext_pairs = []\nfor line in lines:\n    eng, spa = line.split(\"\\t\")\n    spa = \"[start] \" + spa + \" [end]\"\n    text_pairs.append((eng, spa))","metadata":{"id":"EjpdkHtYLQmS","execution":{"iopub.status.busy":"2024-09-19T17:05:40.107606Z","iopub.execute_input":"2024-09-19T17:05:40.107945Z","iopub.status.idle":"2024-09-19T17:05:40.322858Z","shell.execute_reply.started":"2024-09-19T17:05:40.107913Z","shell.execute_reply":"2024-09-19T17:05:40.321997Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Here's what our sentence pairs look like:","metadata":{"id":"Z8RNk9i8LQmT"}},{"cell_type":"code","source":"for _ in range(5):\n    print(random.choice(text_pairs))","metadata":{"id":"3BL3CtdRLQmT","execution":{"iopub.status.busy":"2024-09-19T17:05:42.108134Z","iopub.execute_input":"2024-09-19T17:05:42.108507Z","iopub.status.idle":"2024-09-19T17:05:42.113891Z","shell.execute_reply.started":"2024-09-19T17:05:42.108471Z","shell.execute_reply":"2024-09-19T17:05:42.113006Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"('She stood on her head.', '[start] Ella hizo el pino. [end]')\n('The dog is trying to escape.', '[start] El perro se está tratando de escapar. [end]')\n('I want that information as soon as possible.', '[start] Quiero esa información lo más pronto posible. [end]')\n(\"I'm busy looking for an apartment.\", '[start] Estoy ocupado buscando piso. [end]')\n('Tom wants a detailed explanation.', '[start] Tom quiere una explicación detallada. [end]')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now, let's split the sentence pairs into a training set, a validation set,\nand a test set.","metadata":{"id":"HjfkdPeoLQmU"}},{"cell_type":"code","source":"random.shuffle(text_pairs)\nnum_val_samples = int(0.15 * len(text_pairs))\nnum_train_samples = len(text_pairs) - 2 * num_val_samples\ntrain_pairs = text_pairs[:num_train_samples]\nval_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\ntest_pairs = text_pairs[num_train_samples + num_val_samples :]\n\nprint(f\"{len(text_pairs)} total pairs\")\nprint(f\"{len(train_pairs)} training pairs\")\nprint(f\"{len(val_pairs)} validation pairs\")\nprint(f\"{len(test_pairs)} test pairs\")","metadata":{"id":"GIMwuVQLLQmV","execution":{"iopub.status.busy":"2024-09-19T17:05:45.196966Z","iopub.execute_input":"2024-09-19T17:05:45.197682Z","iopub.status.idle":"2024-09-19T17:05:45.309512Z","shell.execute_reply.started":"2024-09-19T17:05:45.197643Z","shell.execute_reply":"2024-09-19T17:05:45.308630Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"118964 total pairs\n83276 training pairs\n17844 validation pairs\n17844 test pairs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Vectorizing the text data\n\nWe'll use two instances of the `TextVectorization` layer to vectorize the text\ndata (one for English and one for Spanish),\nthat is to say, to turn the original strings into integer sequences\nwhere each integer represents the index of a word in a vocabulary.\n\nThe English layer will use the default string standardization (strip punctuation characters)\nand splitting scheme (split on whitespace), while\nthe Spanish layer will use a custom standardization, where we add the character\n`\"¿\"` to the set of punctuation characters to be stripped.\n\nNote: in a production-grade machine translation model, I would not recommend\nstripping the punctuation characters in either language. Instead, I would recommend turning\neach punctuation character into its own token,\nwhich you could achieve by providing a custom `split` function to the `TextVectorization` layer.","metadata":{"id":"KPFpAyRYLQmV"}},{"cell_type":"code","source":"strip_chars = string.punctuation + \"¿\"\nstrip_chars = strip_chars.replace(\"[\", \"\")\nstrip_chars = strip_chars.replace(\"]\", \"\")\n\nvocab_size = 15000\nsequence_length = 20\nbatch_size = 64\n\n\ndef custom_standardization(input_string):\n    lowercase = tf_strings.lower(input_string)\n    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n\n\neng_vectorization = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length,\n)\nspa_vectorization = TextVectorization(\n    max_tokens=vocab_size,\n    output_mode=\"int\",\n    output_sequence_length=sequence_length + 1,\n    standardize=custom_standardization,\n)\ntrain_eng_texts = [pair[0] for pair in train_pairs]\ntrain_spa_texts = [pair[1] for pair in train_pairs]\neng_vectorization.adapt(train_eng_texts)\nspa_vectorization.adapt(train_spa_texts)","metadata":{"id":"pi3AmbUJLQmW","execution":{"iopub.status.busy":"2024-09-19T17:05:51.178928Z","iopub.execute_input":"2024-09-19T17:05:51.179834Z","iopub.status.idle":"2024-09-19T17:05:52.522686Z","shell.execute_reply.started":"2024-09-19T17:05:51.179688Z","shell.execute_reply":"2024-09-19T17:05:52.521858Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Next, we'll format our datasets.\n\nAt each training step, the model will seek to predict target words N+1 (and beyond)\nusing the source sentence and the target words 0 to N.\n\nAs such, the training dataset will yield a tuple `(inputs, targets)`, where:\n\n- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n`encoder_inputs` is the vectorized source sentence and `encoder_inputs` is the target sentence \"so far\",\nthat is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n- `target` is the target sentence offset by one step:\nit provides the next words in the target sentence -- what the model will try to predict.","metadata":{"id":"3-HlFrDOLQmX"}},{"cell_type":"code","source":"\ndef format_dataset(eng, spa):\n    eng = eng_vectorization(eng)\n    spa = spa_vectorization(spa)\n    return (\n        {\n            \"encoder_inputs\": eng,\n            \"decoder_inputs\": spa[:, :-1],\n        },\n        spa[:, 1:],\n    )\n\n\ndef make_dataset(pairs):\n    eng_texts, spa_texts = zip(*pairs)\n    eng_texts = list(eng_texts)\n    spa_texts = list(spa_texts)\n    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.map(format_dataset)\n    return dataset.cache().shuffle(2048).prefetch(16)\n\n\ntrain_ds = make_dataset(train_pairs)\nval_ds = make_dataset(val_pairs)","metadata":{"id":"RFOMmjx7LQmY","execution":{"iopub.status.busy":"2024-09-19T17:05:58.425930Z","iopub.execute_input":"2024-09-19T17:05:58.426329Z","iopub.status.idle":"2024-09-19T17:05:59.762835Z","shell.execute_reply.started":"2024-09-19T17:05:58.426292Z","shell.execute_reply":"2024-09-19T17:05:59.762014Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Let's take a quick look at the sequence shapes\n(we have batches of 64 pairs, and all sequences are 20 steps long):","metadata":{"id":"QJeyPPuyLQmY"}},{"cell_type":"code","source":"for inputs, targets in train_ds.take(1):\n    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n    print(f\"targets.shape: {targets.shape}\")","metadata":{"id":"BcvzvLICLQmZ","execution":{"iopub.status.busy":"2024-09-19T17:06:08.633968Z","iopub.execute_input":"2024-09-19T17:06:08.634383Z","iopub.status.idle":"2024-09-19T17:06:09.410830Z","shell.execute_reply.started":"2024-09-19T17:06:08.634343Z","shell.execute_reply":"2024-09-19T17:06:09.409872Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"inputs[\"encoder_inputs\"].shape: (64, 20)\ninputs[\"decoder_inputs\"].shape: (64, 20)\ntargets.shape: (64, 20)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Building the model\n\nOur sequence-to-sequence Transformer consists of a `TransformerEncoder`\nand a `TransformerDecoder` chained together. To make the model aware of word order,\nwe also use a `PositionalEmbedding` layer.\n\nThe source sequence will be pass to the `TransformerEncoder`,\nwhich will produce a new representation of it.\nThis new representation will then be passed\nto the `TransformerDecoder`, together with the target sequence so far (target words 0 to N).\nThe `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond).\n\nA key detail that makes this possible is causal masking\n(see method `get_causal_attention_mask()` on the `TransformerDecoder`).\nThe `TransformerDecoder` sees the entire sequences at once, and thus we must make\nsure that it only uses information from target tokens 0 to N when predicting token N+1\n(otherwise, it could use information from the future, which would\nresult in a model that cannot be used at inference time).","metadata":{"id":"hsseyBznLQmZ"}},{"cell_type":"code","source":"import keras.ops as ops\n\n\nclass TransformerEncoder(layers.Layer):\n    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n        self.num_heads = num_heads\n        self.attention = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.dense_proj = keras.Sequential(\n            [\n                layers.Dense(dense_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self, inputs, mask=None):\n        if mask is not None:\n            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n        else:\n            padding_mask = None\n\n        attention_output = self.attention(\n            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n        )\n        proj_input = self.layernorm_1(inputs + attention_output)\n        proj_output = self.dense_proj(proj_input)\n        return self.layernorm_2(proj_input + proj_output)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update(\n            {\n                \"embed_dim\": self.embed_dim,\n                \"dense_dim\": self.dense_dim,\n                \"num_heads\": self.num_heads,\n            }\n        )\n        return config\n\n\nclass PositionalEmbedding(layers.Layer):\n    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n        super().__init__(**kwargs)\n        self.token_embeddings = layers.Embedding(\n            input_dim=vocab_size, output_dim=embed_dim\n        )\n        self.position_embeddings = layers.Embedding(\n            input_dim=sequence_length, output_dim=embed_dim\n        )\n        self.sequence_length = sequence_length\n        self.vocab_size = vocab_size\n        self.embed_dim = embed_dim\n\n    def call(self, inputs):\n        length = ops.shape(inputs)[-1]\n        positions = ops.arange(0, length, 1)\n        embedded_tokens = self.token_embeddings(inputs)\n        embedded_positions = self.position_embeddings(positions)\n        return embedded_tokens + embedded_positions\n\n    def compute_mask(self, inputs, mask=None):\n        if mask is None:\n            return None\n        else:\n            return ops.not_equal(inputs, 0)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update(\n            {\n                \"sequence_length\": self.sequence_length,\n                \"vocab_size\": self.vocab_size,\n                \"embed_dim\": self.embed_dim,\n            }\n        )\n        return config\n\n\nclass TransformerDecoder(layers.Layer):\n    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n        super().__init__(**kwargs)\n        self.embed_dim = embed_dim\n        self.latent_dim = latent_dim\n        self.num_heads = num_heads\n        self.attention_1 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.attention_2 = layers.MultiHeadAttention(\n            num_heads=num_heads, key_dim=embed_dim\n        )\n        self.dense_proj = keras.Sequential(\n            [\n                layers.Dense(latent_dim, activation=\"relu\"),\n                layers.Dense(embed_dim),\n            ]\n        )\n        self.layernorm_1 = layers.LayerNormalization()\n        self.layernorm_2 = layers.LayerNormalization()\n        self.layernorm_3 = layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self, inputs, encoder_outputs, mask=None):\n        causal_mask = self.get_causal_attention_mask(inputs)\n        if mask is not None:\n            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n            padding_mask = ops.minimum(padding_mask, causal_mask)\n        else:\n            padding_mask = None\n\n        attention_output_1 = self.attention_1(\n            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n        )\n        out_1 = self.layernorm_1(inputs + attention_output_1)\n\n        attention_output_2 = self.attention_2(\n            query=out_1,\n            value=encoder_outputs,\n            key=encoder_outputs,\n            attention_mask=padding_mask,\n        )\n        out_2 = self.layernorm_2(out_1 + attention_output_2)\n\n        proj_output = self.dense_proj(out_2)\n        return self.layernorm_3(out_2 + proj_output)\n\n    def get_causal_attention_mask(self, inputs):\n        input_shape = ops.shape(inputs)\n        batch_size, sequence_length = input_shape[0], input_shape[1]\n        i = ops.arange(sequence_length)[:, None]\n        j = ops.arange(sequence_length)\n        mask = ops.cast(i >= j, dtype=\"int32\")\n        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n        mult = ops.concatenate(\n            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n            axis=0,\n        )\n        return ops.tile(mask, mult)\n\n    def get_config(self):\n        config = super().get_config()\n        config.update(\n            {\n                \"embed_dim\": self.embed_dim,\n                \"latent_dim\": self.latent_dim,\n                \"num_heads\": self.num_heads,\n            }\n        )\n        return config\n","metadata":{"id":"up3bFUCXLQma","execution":{"iopub.status.busy":"2024-09-19T17:06:15.632504Z","iopub.execute_input":"2024-09-19T17:06:15.633163Z","iopub.status.idle":"2024-09-19T17:06:15.660497Z","shell.execute_reply.started":"2024-09-19T17:06:15.633121Z","shell.execute_reply":"2024-09-19T17:06:15.659583Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Next, we assemble the end-to-end model.","metadata":{"id":"ZBg3L50RLQma"}},{"cell_type":"code","source":"embed_dim = 256\nlatent_dim = 2048\nnum_heads = 8\n\nencoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\nencoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\nencoder = keras.Model(encoder_inputs, encoder_outputs)\n\ndecoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\nencoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\nx = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\nx = layers.Dropout(0.5)(x)\ndecoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\ndecoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n\ndecoder_outputs = decoder([decoder_inputs, encoder_outputs])\ntransformer = keras.Model(\n    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n)","metadata":{"id":"IUkCKiMhLQmb","execution":{"iopub.status.busy":"2024-09-19T17:06:23.391461Z","iopub.execute_input":"2024-09-19T17:06:23.391853Z","iopub.status.idle":"2024-09-19T17:06:24.117250Z","shell.execute_reply.started":"2024-09-19T17:06:23.391814Z","shell.execute_reply":"2024-09-19T17:06:24.116478Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Training our model\n\nWe'll use accuracy as a quick way to monitor training progress on the validation data.\nNote that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy.\n\nHere we only train for 1 epoch, but to get the model to actually converge\nyou should train for at least 30 epochs.","metadata":{"id":"_QECIMkbLQmb"}},{"cell_type":"code","source":"epochs = 30  # This should be at least 30 for convergence\n\ntransformer.summary()\ntransformer.compile(\n    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n)\ntransformer.fit(train_ds, epochs=epochs, validation_data=val_ds)","metadata":{"id":"uTAoKJrLLQmb","execution":{"iopub.status.busy":"2024-09-19T17:11:43.150600Z","iopub.execute_input":"2024-09-19T17:11:43.150991Z","iopub.status.idle":"2024-09-19T17:36:20.663743Z","shell.execute_reply.started":"2024-09-19T17:11:43.150953Z","shell.execute_reply":"2024-09-19T17:36:20.662806Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"transformer\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_encoder │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embed… │\n│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ functional_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m12,959,640\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_encoder │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ functional_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,959,640</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,920,434\u001b[0m (152.28 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,920,434</span> (152.28 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m19,960,218\u001b[0m (76.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,218</span> (76.14 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1726765908.568516     103 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 611/1302\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 33ms/step - accuracy: 0.8686 - loss: 0.7762","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1726765933.855528     103 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8687 - loss: 0.7762","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1726765962.330708     104 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\nW0000 00:00:1726765963.071852     101 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 40ms/step - accuracy: 0.8687 - loss: 0.7762 - val_accuracy: 0.8746 - val_loss: 0.7292\nEpoch 2/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 36ms/step - accuracy: 0.8791 - loss: 0.6999 - val_accuracy: 0.8800 - val_loss: 0.7029\nEpoch 3/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.8872 - loss: 0.6438 - val_accuracy: 0.8825 - val_loss: 0.6943\nEpoch 4/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.8921 - loss: 0.6122 - val_accuracy: 0.8834 - val_loss: 0.6832\nEpoch 5/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.8970 - loss: 0.5823 - val_accuracy: 0.8847 - val_loss: 0.6946\nEpoch 6/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.9004 - loss: 0.5613 - val_accuracy: 0.8858 - val_loss: 0.6875\nEpoch 7/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - accuracy: 0.9035 - loss: 0.5444 - val_accuracy: 0.8862 - val_loss: 0.6921\nEpoch 8/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.9074 - loss: 0.5231 - val_accuracy: 0.8848 - val_loss: 0.6980\nEpoch 9/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.9089 - loss: 0.5138 - val_accuracy: 0.8867 - val_loss: 0.7091\nEpoch 10/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.9111 - loss: 0.5025 - val_accuracy: 0.8865 - val_loss: 0.7062\nEpoch 11/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 36ms/step - accuracy: 0.9134 - loss: 0.4920 - val_accuracy: 0.8872 - val_loss: 0.7154\nEpoch 12/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 36ms/step - accuracy: 0.9152 - loss: 0.4822 - val_accuracy: 0.8863 - val_loss: 0.7196\nEpoch 13/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 36ms/step - accuracy: 0.9178 - loss: 0.4686 - val_accuracy: 0.8866 - val_loss: 0.7335\nEpoch 14/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 36ms/step - accuracy: 0.9194 - loss: 0.4604 - val_accuracy: 0.8862 - val_loss: 0.7438\nEpoch 15/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.9206 - loss: 0.4560 - val_accuracy: 0.8881 - val_loss: 0.7468\nEpoch 16/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 36ms/step - accuracy: 0.9223 - loss: 0.4458 - val_accuracy: 0.8868 - val_loss: 0.7562\nEpoch 17/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 36ms/step - accuracy: 0.9238 - loss: 0.4382 - val_accuracy: 0.8880 - val_loss: 0.7654\nEpoch 18/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9246 - loss: 0.4366 - val_accuracy: 0.8873 - val_loss: 0.7689\nEpoch 19/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9259 - loss: 0.4283 - val_accuracy: 0.8867 - val_loss: 0.7858\nEpoch 20/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9276 - loss: 0.4200 - val_accuracy: 0.8870 - val_loss: 0.7864\nEpoch 21/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9289 - loss: 0.4132 - val_accuracy: 0.8882 - val_loss: 0.7906\nEpoch 22/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9303 - loss: 0.4085 - val_accuracy: 0.8864 - val_loss: 0.7979\nEpoch 23/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9309 - loss: 0.4048 - val_accuracy: 0.8882 - val_loss: 0.8011\nEpoch 24/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9322 - loss: 0.3984 - val_accuracy: 0.8871 - val_loss: 0.8145\nEpoch 25/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9330 - loss: 0.3957 - val_accuracy: 0.8882 - val_loss: 0.8204\nEpoch 26/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - accuracy: 0.9344 - loss: 0.3870 - val_accuracy: 0.8877 - val_loss: 0.8224\nEpoch 27/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 36ms/step - accuracy: 0.9350 - loss: 0.3851 - val_accuracy: 0.8881 - val_loss: 0.8415\nEpoch 28/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9352 - loss: 0.3839 - val_accuracy: 0.8848 - val_loss: 0.8499\nEpoch 29/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9365 - loss: 0.3773 - val_accuracy: 0.8868 - val_loss: 0.8652\nEpoch 30/30\n\u001b[1m1302/1302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 35ms/step - accuracy: 0.9370 - loss: 0.3765 - val_accuracy: 0.8873 - val_loss: 0.8526\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f0ab47f00a0>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Decoding test sentences\n\nFinally, let's demonstrate how to translate brand new English sentences.\nWe simply feed into the model the vectorized English sentence\nas well as the target token `\"[start]\"`, then we repeatedly generated the next token, until\nwe hit the token `\"[end]\"`.","metadata":{"id":"FlCjJhyfLQmc"}},{"cell_type":"code","source":"spa_vocab = spa_vectorization.get_vocabulary()\nspa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\nmax_decoded_sentence_length = 20\n\n\ndef decode_sequence(input_sentence):\n    tokenized_input_sentence = eng_vectorization([input_sentence])\n    decoded_sentence = \"[start]\"\n    for i in range(max_decoded_sentence_length):\n        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n\n        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n        sampled_token_index = ops.convert_to_numpy(\n            ops.argmax(predictions[0, i, :])\n        ).item(0)\n        sampled_token = spa_index_lookup[sampled_token_index]\n        decoded_sentence += \" \" + sampled_token\n\n        if sampled_token == \"[end]\":\n            break\n    return decoded_sentence\n\n\ntest_eng_texts = [pair[0] for pair in test_pairs]\nfor _ in range(30):\n    input_sentence = random.choice(test_eng_texts)\n    translated = decode_sequence(input_sentence)\n    print(input_sentence ,translated)","metadata":{"id":"HsjPXo7wLQmc","execution":{"iopub.status.busy":"2024-09-19T17:40:37.331125Z","iopub.execute_input":"2024-09-19T17:40:37.332090Z","iopub.status.idle":"2024-09-19T17:40:50.431842Z","shell.execute_reply.started":"2024-09-19T17:40:37.332014Z","shell.execute_reply":"2024-09-19T17:40:50.430922Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"The climate here is very similar to that of England. [start] el clima de clima muy similares al de inglaterra [end]\nIf I were more creative, I would try to write music. [start] si hubiera más [UNK] más estáis tratando de escribir una música [end]\nI am very glad to meet you today. [start] estoy muy contento de encontrarte hoy [end]\nMy apartment isn't far from here. [start] mi departamento no está lejos de aquí [end]\nThe hawk caught a rat. [start] el [UNK] pescó un ratón [end]\nIt's raining here. [start] está lloviendo aquí [end]\nTom is a complete failure as a father. [start] tom es un completo fracaso como padre [end]\nI love you more than you love me. [start] te quiero más que me amas [end]\nWe are baking cookies. [start] estamos preparando y galletas [end]\nI liked this film. [start] me gustaba esta película [end]\nThis is a good learning environment. [start] este es un buen proyecto del medio ambiente [end]\nHow do you know Tom is there? [start] cómo sabes que tom está allí [end]\nWe were unsuccessful. [start] eran un ruido [end]\nTell me why she is crying. [start] dime por qué ella está llorando [end]\nThat's something I couldn't do. [start] eso es algo que no podía hacer [end]\nHe climbed into his car. [start] se subió a su coche [end]\nThat's the house I stayed in. [start] esa es la casa en el que me quedé [end]\nLock the door! [start] cierra la llave a la llave [end]\nDid you buy a washing machine? [start] has comprado una lavadora [end]\nI suppose you want to ask me where I was yesterday afternoon. [start] supongo que querría preguntarme dónde estaba ayer por la tarde [end]\nTell me about your first kiss. [start] dime alguna vez [end]\nTom needs to speak to Mary. [start] tom tiene que hablar con maría [end]\nI liked Tom. [start] me gustaba a tom [end]\nIn the end, he did not come. [start] al final no ha llegado él no [end]\nShe'd rather be spending time with someone else. [start] preferiría estar pasar tiempo con alguien más [end]\nWomen talk nonstop. [start] las mujeres hablan sin palabras [end]\nLet's learn this poem by heart. [start] hablemos este poema de memoria [end]\nWhy are you so worried? [start] por qué estás tan preocupada [end]\nWhy did you allow it to happen? [start] por qué lo has pasado a pasar [end]\nCall an exterminator. [start] llama a un [UNK] [end]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After 30 epochs, we get results such as:\n\n> She handed him the money.\n> [start] ella le pasó el dinero [end]\n\n> Tom has never heard Mary sing.\n> [start] tom nunca ha oído cantar a mary [end]\n\n> Perhaps she will come tomorrow.\n> [start] tal vez ella vendrá mañana [end]\n\n> I love to write.\n> [start] me encanta escribir [end]\n\n> His French is improving little by little.\n> [start] su francés va a [UNK] sólo un poco [end]\n\n> My hotel told me to call you.\n> [start] mi hotel me dijo que te [UNK] [end]","metadata":{"id":"BCUawGlvLQmc"}}]}